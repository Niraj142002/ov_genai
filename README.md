Running GenAI on Intel AI Laptops

Project Overview
The project "Running GenAI on Intel AI Laptops and Simple LLM Inference on CPU and fine-tuning of LLM Models using Intel¬Æ OpenVINOTM" aims to develop an AI solution for generating Past match summaries of cricket matches. This involves training Large Language Models (LLMs) with frameworks such as Hugging Face, and PyTorch, and optimizing these models using Intel¬Æ OpenVINOTM for efficient CPU inference on Intel AI laptops.

üßê Features
Here're some of the project's best features:
Past match‚Äôs cricket match summarization.
Utilizes advanced AI frameworks: Hugging Face, and PyTorch.
Optimized model performance using Intel¬Æ OpenVINOTM.
User-friendly interface for easy interaction.

Objectives
Develop a scalable AI solution for Past match summarization.
Train and optimize LLMs for efficient CPU inference on Intel AI laptops.
Enhance summarization accuracy and performance.
Provide hands-on learning opportunities in machine learning and NLP.
Explore future applications and innovations in AI-driven summarization.

Process Flow
Model Development:
Train AI models using frameworks like Hugging Face and PyTorch.
Optimization:
Optimize models with Intel¬Æ OpenVINOTM for efficient CPU inference.

Frontend Integration:
Develop a user-friendly interface for displaying match summaries.

Deployment and Testing:
Deploy and rigorously test the AI model to ensure accuracy and efficiency.



Technologies Used
AI Frameworks		      	: PyTorch.
Frontend Development		: Flask, HTML, CSS.
Model Optimization 	  	: Intel¬Æ OpenVINOTM Toolkit.
Model Formats			     	: ONNX, XML, BIN.
Model 			        		: Tinyllama.
Hub 				        		: Hugging Face.
Deployment		      		: Intel AI laptops

Team Members and Contributions
Niraj Patil (Leader)  : Model training, Model building, frontend development, project management and Completion.
Yash Mehta            : Model development and training, backend integration with OpenVINOTM.
Ganesh Patil          : Frontend development.
Sumeet                : Converting AI model to BART model/ONNX model.
Dushyant              : Integration with OpenVINOTM.

Problem Statement
This project addresses challenges in Generative AI, particularly in using Large Language Models (LLMs) for summarization tasks. It provides practical experience in handling large pre-trained models, optimizing LLM inference on CPUs, and fine-tuning LLMs for custom applications like chatbots. Participants gain hands-on knowledge in machine learning and NLP, utilizing Intel AI tools for efficient model deployment and performance enhancement.

Conclusion
The project successfully demonstrates the potential of integrating advanced AI frameworks with Intel‚Äôs optimization tools to improve user experiences in sports information dissemination. It highlights the feasibility and benefits of deploying GenAI on Intel AI laptops, setting the stage for future advancements in AI-driven applications.

